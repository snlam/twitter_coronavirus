# Coronavirus analysis

This repository analyzes the activity of coronavirus hashtags of 1.1 billion geotagged tweets from 2020 using MapReduce.

# Data Setup
The dataset was pre-partitioned into 365 zip files where each zip file contains all of the tweets for a day of the year. Each of these daily zip files contains 24 text files, which corresponds to one text file for each hour of the day. Each text file contains all of the tweets made during that hour in JSON format, with one tweet per line.

# Map
The `src/map.py` file processes the partitioned zip file by extracting the language and origin country of the tweets containing the hashtags listed below:
```
    - #코로나바이러스  # korean
    - #コロナウイルス  # japanese
    - #冠状病毒        # chinese
    - #covid2019
    - #covid-2019
    - #covid19
    - #covid-19
    - #coronavirus
    - #corona
    - #virus
    - #flu
    - #sick
    - #cough
    - #sneeze
    - #hospital
    - #nurse
    - #doctor
```
After mapping each daily zip file, a `.lang` and a `.country` text files are generated in the `outputs` folder. They contain the counts of the language and the origin country of tweets containing each hashtag in the list. If no country was indicated, the country code "UND" was used, standing for undetermined language.

`run_maps.sh` automates this process by calling `src/map.py` on all of the partitioned zip files, running in parallel.

# Reduce
The `src/reduce.py` file merges the outputs generated by the calls to map.py so that we can analyze the dataset for all of 2020 as a whole instead of analyzing the data per day. This is done for both the `.lang` and `.country` files:
```
./src/reduce.py --input_paths outputs/*.lang --output_path=reduced.lang
./src/reduce.py --input_paths outputs/*.country --output_path=reduced.country
```

# Visualize
The `src/visualize.py` file separates the data in the reduced files by hashtag and formats them to be more human-readable. `run_visualizes.sh` automates visualizing the hashtags by language and country. It also uses the `head` command to only output the top 10 results for language/country for each hashtag. The visualized data is outputted in the `viz/` folder.

# Results
English is the most common language of these tweets, and the United States (US) is the most common country of these tweets. This makes sense for 3 reasons: most of the tweets use English hashtags, the United States tends to be overrepresented in internet data in general, and the coronavirus pandemic was particularly severe in the United States. 
For the non-English hashtags, the most common language and origin country of those tweets is the same as the language (and corresponding country) of the hashtag.
